{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/wueesmat/MT/anomalib')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "current_directory = Path.cwd()\n",
    "if current_directory.name == \"MT\":\n",
    "    # This means that the notebook is run from the main anomalib directory.\n",
    "    root_directory = current_directory.parent\n",
    "elif current_directory.name == \"anomalib\":\n",
    "    # This means that the notebook is run from the main anomalib directory.\n",
    "    root_directory = current_directory\n",
    "\n",
    "os.chdir(root_directory)\n",
    "root_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find wandb. To use this feature, ensure that you have wandb installed.\n",
      "Could not find openvino. To use this feature, ensure that you have openvino installed.\n",
      "OpenVINO is not installed. Please install OpenVINO to use OpenVINOInferencer.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Import the required modules\n",
    "from lightning.pytorch import Trainer, seed_everything\n",
    "from anomalib.data import MVTec\n",
    "from anomalib.data.image.mvtec import MVTec_contaminated\n",
    "from anomalib.models import Padim, Patchcore, Stfpm, Draem, EfficientAd\n",
    "from anomalib.engine import Engine\n",
    "from anomalib import TaskType\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n"
     ]
    }
   ],
   "source": [
    "for idx_category, category in enumerate(category_arr):\n",
    "    print(results_arr[0,:,idx_category])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(results_arr[0,:,:],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(results_arr[1,:,:],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(results_arr[2,:,:],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results_arr to a file\n",
    "np.save(\"results_arr.npy\", results_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"./results/EfficientAD/\" #\"./results/Padim/\"\n",
    "name = \"EfficientAD_20240327.npy\" #\"Padim_20240327.npy\"\n",
    "file_path = os.path.join(save_folder, name)\n",
    "np.save(file_path, results_arr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wueesmat/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/lightning/fabric/plugins/environments/slurm.py:191: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /home/wueesmat/anaconda3/envs/anomalib_env/lib/pytho ...\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n",
      "/home/wueesmat/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/torchmetrics/utilities/prints.py:36: UserWarning: Metric `PrecisionRecallCurve` will save all targets and predictions in buffer. For large datasets this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "F1Score class exists for backwards compatibility. It will be removed in v1.1. Please use BinaryF1Score from torchmetrics instead\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m engine \u001b[38;5;241m=\u001b[39m Engine(task\u001b[38;5;241m=\u001b[39mTaskType\u001b[38;5;241m.\u001b[39mCLASSIFICATION, image_metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUROC\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAUPR\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1Score\u001b[39m\u001b[38;5;124m\"\u001b[39m], max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, devices\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# load best model from checkpoint before evaluating\u001b[39;00m\n\u001b[1;32m     26\u001b[0m test_results \u001b[38;5;241m=\u001b[39m engine\u001b[38;5;241m.\u001b[39mtest(\n\u001b[1;32m     27\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     28\u001b[0m     datamodule\u001b[38;5;241m=\u001b[39mdatamodule,\n\u001b[1;32m     29\u001b[0m     ckpt_path\u001b[38;5;241m=\u001b[39mengine\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mcheckpoint_callback\u001b[38;5;241m.\u001b[39mbest_model_path,\n\u001b[1;32m     30\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     31\u001b[0m )\n",
      "File \u001b[0;32m~/MT/anomalib/src/anomalib/engine/engine.py:515\u001b[0m, in \u001b[0;36mEngine.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mvalidate(model, val_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule, ckpt_path\u001b[38;5;241m=\u001b[39mckpt_path)\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 515\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:544\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 544\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/lightning/pytorch/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:580\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    574\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    575\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    576\u001b[0m     ckpt_path,\n\u001b[1;32m    577\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    579\u001b[0m )\n\u001b[0;32m--> 580\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/lightning/pytorch/trainer/trainer.py:965\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m    964\u001b[0m \u001b[38;5;66;03m# strategy will configure model and move it to the device\u001b[39;00m\n\u001b[0;32m--> 965\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstrategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;241m==\u001b[39m TrainerFn\u001b[38;5;241m.\u001b[39mFITTING:\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/lightning/pytorch/strategies/single_device.py:77\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.setup\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup\u001b[39m(\u001b[38;5;28mself\u001b[39m, trainer: pl\u001b[38;5;241m.\u001b[39mTrainer) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39msetup(trainer)\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/lightning/pytorch/strategies/single_device.py:74\u001b[0m, in \u001b[0;36mSingleDeviceStrategy.model_to_device\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodel_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself.model must be set before self.model.to()\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 74\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroot_device\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/lightning/fabric/utilities/device_dtype_mixin.py:54\u001b[0m, in \u001b[0;36m_DeviceDtypeModuleMixin.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     52\u001b[0m device, dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39m_parse_to(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m     53\u001b[0m _update_properties(\u001b[38;5;28mself\u001b[39m, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1160\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 810 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/torch/nn/modules/module.py:810\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    809\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 810\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    814\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/torch/nn/modules/module.py:833\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 833\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    835\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/envs/anomalib_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1158\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1157\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "save_folder = \"./results/Padim/\"#\"./results/Stfpm/\" # \n",
    "name = \"Padim_20240328.npy\"#\"Stfpm_20240328.npy\" # \n",
    "file_path = os.path.join(save_folder, name)\n",
    "file_path\n",
    "\n",
    "run_arr = np.array([1]) #np.array([1, 2, 3]) #np.array([42])#np.arange(3)+1\n",
    "cont_ratio_arr = np.array([0.0])#, 0.1]) #np.array([0.0, 0.05, 0.1]) #, 0.15\n",
    "category_arr = np.array([\"carpet\"])#, \"grid\"])#np.array([\"carpet\", \"grid\", \"leather\", \"tile\", \"wood\", \"bottle\", \"cable\", \"capsule\", \"hazelnut\", \"metal_nut\", \"pill\", \"screw\", \"toothbrush\", \"transistor\", \"zipper\"])#np.array([\"carpet\", \"grid\"]) #\n",
    "results_arr = np.empty([run_arr.shape[0], cont_ratio_arr.shape[0], category_arr.shape[0]])\n",
    "\n",
    "for idx_run, run in enumerate(run_arr):\n",
    "    for idx_cont_ratio, cont_ratio in enumerate(cont_ratio_arr):\n",
    "        for idx_category, category in enumerate(category_arr):\n",
    "\n",
    "            #seed_everything(run, workers=True)\n",
    "            datamodule = MVTec_contaminated(category=category, cont_ratio=cont_ratio, run=run)\n",
    "            model = Padim(backbone=\"resnet18\", n_features=100, layers=[\"layer1\", \"layer2\", \"layer3\"])\n",
    "            #model = EfficientAd()\n",
    "            #model = Stfpm()\n",
    "            engine = Engine(task=TaskType.CLASSIFICATION, image_metrics=[\"AUROC\", \"AUPR\", \"F1Score\"], max_epochs=10, devices=1)\n",
    "\n",
    "            # Train the model\n",
    "            engine.fit(datamodule=datamodule, model=model)\n",
    "\n",
    "            # load best model from checkpoint before evaluating\n",
    "            test_results = engine.test(\n",
    "                model=model,\n",
    "                datamodule=datamodule,\n",
    "                ckpt_path=engine.trainer.checkpoint_callback.best_model_path,\n",
    "                verbose=False\n",
    "            )\n",
    "            test_results\n",
    "            results_arr[idx_run, idx_cont_ratio, idx_category] = test_results[0][\"image_AUROC\"]\n",
    "            \n",
    "            print(run)\n",
    "            print(cont_ratio)\n",
    "            print(category)\n",
    "\n",
    "# Save results_arr to the specified folder\n",
    "np.save(file_path, results_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_folder = \"./results/Patchcore/\"#\"./results/Stfpm/\" # \n",
    "name = \"Patchcore_all_categories_cont_max_0.15_runs_10_20240331.npy\" #\"Patchcore_cont_max_0.15_20240328.npy\" # \"Patchcore_20240328.npy\"# \n",
    "file_path = os.path.join(save_folder, name)\n",
    "file_path\n",
    "\n",
    "# Load the saved array\n",
    "loaded_array = np.load(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99464285, 0.99567101, 1.        , 0.98953167, 0.98513938,\n",
       "        1.        , 0.98705274, 0.97379056, 0.99999995, 0.99834718,\n",
       "        0.94312601, 0.98265584, 0.99833325, 0.9988889 , 0.99480517],\n",
       "       [0.99571431, 0.99220777, 1.        , 0.98884294, 0.97275546,\n",
       "        1.        , 0.98132725, 0.97428044, 1.        , 0.99090911,\n",
       "        0.93952537, 0.98211381, 0.99749994, 1.        , 0.98685063],\n",
       "       [0.99696426, 0.98701301, 0.99974489, 0.98980716, 0.97213626,\n",
       "        1.        , 0.97397528, 0.97232088, 0.99999998, 0.98413225,\n",
       "        0.93101473, 0.9783198 , 0.99750001, 0.9988889 , 0.98279219],\n",
       "       [0.99642859, 0.98874459, 0.99987245, 0.98966942, 0.97027867,\n",
       "        1.        , 0.95810019, 0.96962645, 1.        , 0.97669425,\n",
       "        0.92986908, 0.97313201, 0.99750001, 0.99555557, 0.97897726]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(loaded_array, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99464285 0.99571431 0.99696426 0.99642859]\n",
      "[0.99567101 0.99220777 0.98701301 0.98874459]\n",
      "[1.         1.         0.99974489 0.99987245]\n",
      "[0.98953167 0.98884294 0.98980716 0.98966942]\n",
      "[0.98513938 0.97275546 0.97213626 0.97027867]\n",
      "[1. 1. 1. 1.]\n",
      "[0.98705274 0.98132725 0.97397528 0.95810019]\n",
      "[0.97379056 0.97428044 0.97232088 0.96962645]\n",
      "[0.99999995 1.         0.99999998 1.        ]\n",
      "[0.99834718 0.99090911 0.98413225 0.97669425]\n",
      "[0.94312601 0.93952537 0.93101473 0.92986908]\n",
      "[0.98265584 0.98211381 0.9783198  0.97313201]\n",
      "[0.99833325 0.99749994 0.99750001 0.99750001]\n",
      "[0.9988889  1.         0.9988889  0.99555557]\n",
      "[0.99480517 0.98685063 0.98279219 0.97897726]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,15):\n",
    "    print(np.mean(loaded_array, axis=0)[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0017857313156127708\n",
      "0.006926417350769043\n",
      "0.00012755393981933594\n",
      "-0.00013774633407592773\n",
      "0.014860713481902987\n",
      "0.0\n",
      "0.02895255088806148\n",
      "0.0041641116142272505\n",
      "-4.768371586472142e-08\n",
      "0.021652925014495783\n",
      "0.013256931304931663\n",
      "0.009523820877075151\n",
      "0.0008332371711731179\n",
      "0.0033333301544189453\n",
      "0.01582790613174434\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,15):\n",
    "    perf_loss = np.mean(loaded_array, axis=0)[0,i]-np.mean(loaded_array, axis=0)[3,i]\n",
    "    print(perf_loss)\n",
    "perf_loss_arr = np.mean(loaded_array, axis=0)[0,:]-np.mean(loaded_array, axis=0)[3,:]\n",
    "perf_std_arr = np.std(loaded_array, axis=0)[0,:]-np.std(loaded_array, axis=0)[3,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.14375489e-03, -6.41286591e-03, -2.55107880e-04,  8.74962362e-04,\n",
       "       -1.62052271e-03,  0.00000000e+00, -6.30504374e-03, -3.60000384e-03,\n",
       "        5.84003864e-08, -9.79959802e-03, -2.01926975e-03, -1.31701674e-03,\n",
       "       -1.29210416e-03, -6.66666031e-03, -7.54060668e-04])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_std_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.79959802e-03, -6.66666031e-03, -6.41286591e-03, -6.30504374e-03,\n",
       "       -3.60000384e-03, -2.01926975e-03, -1.62052271e-03, -1.31701674e-03,\n",
       "       -1.29210416e-03, -1.14375489e-03, -7.54060668e-04, -2.55107880e-04,\n",
       "        0.00000000e+00,  5.84003864e-08,  8.74962362e-04])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(perf_std_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.78573132e-03,  6.92641735e-03,  1.27553940e-04, -1.37746334e-04,\n",
       "        1.48607135e-02,  0.00000000e+00,  2.89525509e-02,  4.16411161e-03,\n",
       "       -4.76837159e-08,  2.16529250e-02,  1.32569313e-02,  9.52382088e-03,\n",
       "        8.33237171e-04,  3.33333015e-03,  1.58279061e-02])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perf_loss_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.78573132e-03, -1.37746334e-04, -4.76837159e-08,  0.00000000e+00,\n",
       "        1.27553940e-04,  8.33237171e-04,  3.33333015e-03,  4.16411161e-03,\n",
       "        6.92641735e-03,  9.52382088e-03,  1.32569313e-02,  1.48607135e-02,\n",
       "        1.58279061e-02,  2.16529250e-02,  2.89525509e-02])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort(perf_loss_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cable, metal nut, transistor, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00556156 0.00647299 0.00563562 0.00670531]\n",
      "[0.00474219 0.00793521 0.01161592 0.01115505]\n",
      "[0.         0.         0.00031244 0.00025511]\n",
      "[0.01002199 0.01022813 0.00928498 0.00914703]\n",
      "[0.01362229 0.01457416 0.01253778 0.01524281]\n",
      "[0. 0. 0. 0.]\n",
      "[0.00455152 0.0066656  0.01163314 0.01085657]\n",
      "[0.00357914 0.00446649 0.0042673  0.00717914]\n",
      "[5.84003864e-08 0.00000000e+00 4.76837158e-08 0.00000000e+00]\n",
      "[0.0018107  0.007682   0.00868987 0.0116103 ]\n",
      "[0.00894942 0.00833491 0.00802049 0.01096868]\n",
      "[0.00596959 0.00397383 0.00518833 0.00728661]\n",
      "[0.00204122 0.0033333  0.00204123 0.00333332]\n",
      "[0.0022222  0.         0.0022222  0.00888886]\n",
      "[0.00303055 0.00346851 0.0045382  0.00378461]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,15):\n",
    "    print(np.std(loaded_array, axis=0)[:,i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.99999994, 1.        , 1.        , 0.99586773, 1.        ,\n",
       "         1.        , 0.99121672, 0.9748928 , 0.99999988, 0.99504131,\n",
       "         0.92839605, 0.97328687, 0.99583328, 1.        , 0.99756491],\n",
       "        [1.        , 1.        , 1.        , 0.99517894, 1.00000012,\n",
       "         1.        , 0.98503572, 0.96876913, 1.        , 0.97851235,\n",
       "         0.92348611, 0.98180419, 0.99166667, 1.        , 0.98985386],\n",
       "        [1.        , 1.        , 1.        , 0.99449027, 0.99690413,\n",
       "         1.        , 0.98113203, 0.97305572, 1.        , 0.98016536,\n",
       "         0.91693938, 0.98335272, 0.9958334 , 1.        , 0.98457789],\n",
       "        [1.        , 1.        , 1.        , 0.99586773, 1.00000012,\n",
       "         1.        , 0.96844506, 0.97366816, 1.        , 0.96115708,\n",
       "         0.90916532, 0.96980256, 0.99166667, 1.        , 0.98295456]],\n",
       "\n",
       "       [[1.        , 1.        , 1.        , 0.97451794, 0.97213626,\n",
       "         1.        , 0.98893952, 0.97428048, 1.        , 1.00000012,\n",
       "         0.94885433, 0.98722416, 0.99583328, 1.        , 0.99594152],\n",
       "        [0.99999994, 1.        , 1.        , 0.97451782, 0.96594429,\n",
       "         1.        , 0.97592711, 0.97979176, 1.        , 0.99834716,\n",
       "         0.94189847, 0.98373973, 0.99583328, 1.        , 0.98863637],\n",
       "        [1.        , 1.        , 0.99936223, 0.97933888, 0.96284831,\n",
       "         1.        , 0.97462595, 0.96999383, 1.        , 0.99752069,\n",
       "         0.93657935, 0.96980262, 0.99583328, 1.        , 0.99066556],\n",
       "        [1.        , 1.        , 1.        , 0.97865021, 0.96594429,\n",
       "         1.        , 0.94925183, 0.9736681 , 1.        , 0.98760331,\n",
       "         0.93166935, 0.97677124, 1.        , 1.        , 0.98133117]],\n",
       "\n",
       "       [[0.99375004, 0.98701298, 1.        , 0.9965564 , 0.99071217,\n",
       "         1.        , 0.98893952, 0.97244334, 1.        , 0.99834716,\n",
       "         0.93903434, 0.98838562, 0.99999988, 1.        , 0.99675322],\n",
       "        [0.99642861, 0.97835493, 1.        , 0.99586773, 0.97523224,\n",
       "         1.        , 0.97364992, 0.97305572, 1.        , 0.99173558,\n",
       "         0.94558102, 0.97793269, 0.99999988, 1.        , 0.98944807],\n",
       "        [0.99910712, 0.98268402, 1.        , 0.99724519, 0.96594429,\n",
       "         1.        , 0.9739753 , 0.97183108, 1.        , 0.98760331,\n",
       "         0.92880529, 0.97483546, 1.        , 1.        , 0.98133117],\n",
       "        [0.99910712, 0.98701298, 1.        , 0.99517894, 0.96284831,\n",
       "         1.        , 0.9450227 , 0.97305578, 1.        , 0.98842978,\n",
       "         0.93985271, 0.96747971, 1.        , 1.        , 0.98173702]],\n",
       "\n",
       "       [[0.99464285, 0.99567103, 1.        , 1.        , 0.96594435,\n",
       "         1.        , 0.98796356, 0.9791795 , 0.99999988, 1.00000012,\n",
       "         0.95458263, 0.98644984, 0.99999994, 0.99444449, 0.98904216],\n",
       "        [0.99910712, 0.99134195, 1.        , 1.        , 0.96284831,\n",
       "         1.        , 0.99219263, 0.97060627, 1.        , 0.98677683,\n",
       "         0.9402619 , 0.98877269, 0.99999988, 1.        , 0.98051941],\n",
       "        [0.99999994, 0.98268402, 1.        , 1.        , 0.96594429,\n",
       "         1.        , 0.98731291, 0.97979176, 1.        , 0.9710744 ,\n",
       "         0.94026184, 0.98219126, 1.        , 0.99444449, 0.97767854],\n",
       "        [1.        , 0.969697  , 1.        , 1.        , 0.95665634,\n",
       "         1.        , 0.97299933, 0.97244328, 1.        , 0.96446288,\n",
       "         0.93821609, 0.98567557, 0.9958334 , 0.97777784, 0.97362012]],\n",
       "\n",
       "       [[0.98482144, 0.99567103, 1.        , 0.98071629, 0.99690413,\n",
       "         1.        , 0.97820437, 0.9681567 , 1.        , 0.99834716,\n",
       "         0.94476271, 0.97793269, 0.99999988, 1.        , 0.99472404],\n",
       "        [0.98303586, 0.99134195, 1.        , 0.97865021, 0.95975232,\n",
       "         1.        , 0.97983086, 0.97917932, 1.        , 0.99917364,\n",
       "         0.94639933, 0.97831976, 1.        , 1.        , 0.98579544],\n",
       "        [0.98571426, 0.969697  , 0.99936223, 0.97796148, 0.96904027,\n",
       "         1.        , 0.9528302 , 0.966932  , 0.99999988, 0.98429751,\n",
       "         0.93248779, 0.98141694, 0.9958334 , 1.        , 0.97970778],\n",
       "        [0.9830358 , 0.98701298, 0.99936223, 0.97865021, 0.96594429,\n",
       "         1.        , 0.95478201, 0.95529693, 1.        , 0.9818182 ,\n",
       "         0.93044192, 0.965931  , 1.        , 1.        , 0.97524345]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.99121672, 1.        , 0.99999988],\n",
       "        [0.98503572, 1.        , 1.        ],\n",
       "        [0.98113203, 1.        , 1.        ],\n",
       "        [0.96844506, 1.        , 1.        ]],\n",
       "\n",
       "       [[0.98893952, 1.        , 1.        ],\n",
       "        [0.97592711, 1.        , 1.        ],\n",
       "        [0.97462595, 1.        , 1.        ],\n",
       "        [0.94925183, 1.        , 1.        ]],\n",
       "\n",
       "       [[0.98893952, 1.        , 1.        ],\n",
       "        [0.97364992, 1.        , 1.        ],\n",
       "        [0.9739753 , 1.        , 1.        ],\n",
       "        [0.9450227 , 1.        , 1.        ]],\n",
       "\n",
       "       [[0.98796356, 0.99444449, 0.99999988],\n",
       "        [0.99219263, 1.        , 1.        ],\n",
       "        [0.98731291, 0.99444449, 1.        ],\n",
       "        [0.97299933, 0.97777784, 1.        ]],\n",
       "\n",
       "       [[0.97820437, 1.        , 1.        ],\n",
       "        [0.97983086, 1.        , 1.        ],\n",
       "        [0.9528302 , 1.        , 0.99999988],\n",
       "        [0.95478201, 1.        , 1.        ]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the datamodule, model and engine\n",
    "#datamodule = MVTec(category=\"carpet\")\n",
    "#datamodule = MVTec_contaminated(category=\"carpet\")\n",
    "seed_everything(2, workers=True)\n",
    "category = \"carpet\"\n",
    "cont_ratio=0.1#0.05#0.1#0 #0.05\n",
    "datamodule = MVTec_contaminated(category=category, cont_ratio=cont_ratio, run=2)\n",
    "#model = Padim(backbone=\"wide_resnet50_2\", n_features=550, layers=[\"layer1\", \"layer2\", \"layer3\"]) #EfficientAd() #Draem() #Patchcore() #Stfpm()\n",
    "model = Padim(backbone=\"resnet18\", n_features=100, layers=[\"layer1\", \"layer2\", \"layer3\"])\n",
    "engine = Engine(task=TaskType.CLASSIFICATION, image_metrics=[\"AUROC\", \"AUPR\", \"F1Score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "engine.fit(datamodule=datamodule, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model from checkpoint before evaluating\n",
    "test_results = engine.test(\n",
    "    model=model,\n",
    "    datamodule=datamodule,\n",
    "    ckpt_path=engine.trainer.checkpoint_callback.best_model_path,\n",
    "    verbose=False\n",
    ")\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[{'image_AUROC': 0.8588435053825378, 'image_F1Score': 0.8253968358039856}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results[0][\"image_AUROC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch import Trainer, seed_everything\n",
    "import numpy as np\n",
    "\n",
    "seed_everything(1, workers=True)\n",
    "\n",
    "\n",
    "#model = Padim(backbone=\"wide_resnet50_2\", n_features=550, layers=[\"layer1\", \"layer2\", \"layer3\"]) #EfficientAd() #Draem() #Patchcore() #\n",
    "model = Padim(backbone=\"resnet18\", n_features=100, layers=[\"layer1\", \"layer2\", \"layer3\"])\n",
    "#model = Padim()\n",
    "engine = Engine(task=TaskType.CLASSIFICATION)\n",
    "\n",
    "category_arr = np.array([\"carpet\", \"grid\", \"leather\", \"tile\", \"wood\", \"bottle\", \"cable\", \"capsule\", \"hazelnut\", \"metal_nut\", \"pill\", \"screw\", \"toothbrush\", \"transistor\", \"zipper\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_AUROC_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(image_AUROC_ls,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(image_AUROC_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(image_AUROC_ls,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(image_AUROC_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_AUROC_ls = []\n",
    "image_F1Score_ls = []\n",
    "category_arr_short = category_arr#[0:2]\n",
    "for idx, category in enumerate(category_arr_short):\n",
    "    print(category)\n",
    "\n",
    "    # Initialize the datamodule, model and engine\n",
    "    seed_everything(42, workers=True)\n",
    "    datamodule = MVTec(category=category)\n",
    "    #model = Padim(backbone=\"resnet18\", n_features=100, layers=[\"layer1\", \"layer2\", \"layer3\"])\n",
    "    #model = Padim(backbone=\"wide_resnet50_2\", n_features=550, layers=[\"layer1\", \"layer2\", \"layer3\"]) #EfficientAd() #Draem() #Patchcore() \n",
    "    model = Patchcore(backbone=\"wide_resnet50_2\") \n",
    "    engine = Engine(task=TaskType.CLASSIFICATION)\n",
    "    \n",
    "    # Train the model\n",
    "    engine.fit(datamodule=datamodule, model=model)\n",
    "\n",
    "    # load best model from checkpoint before evaluating\n",
    "    test_results = engine.test(\n",
    "        model=model,\n",
    "        datamodule=datamodule,\n",
    "        ckpt_path=engine.trainer.checkpoint_callback.best_model_path,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    image_F1Score_ls.append(test_results[0]['image_F1Score'])\n",
    "    image_AUROC_ls.append(test_results[0]['image_AUROC'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_F1Score_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_F1Score_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(image_F1Score_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_ls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "al_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
